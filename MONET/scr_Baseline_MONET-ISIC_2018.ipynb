{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5013f9fb-d099-41f3-bfa3-7939403bae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import scipy.special\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94331173-6f32-4d81-b89b-4db23bdeca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0a5da56-4dd9-4ea7-891b-80476b3d84c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "\"\"\"\n",
    "Choose accordingly to the Model/Dataset being evaluated:\n",
    "MODEL= {ViT-L-14} \n",
    "DATASET= {ISIC_2018}\n",
    "\"\"\"\n",
    "\n",
    "MODEL = \"ViT-L-14\"\n",
    "DATASET = \"ISIC_2018\"\n",
    "ADDITIONAL_COMMENTS = \"CLASS_LABELS_PROMPTS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91860e0c-e038-48f1-b84b-8c2d77704a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_LABELS_PROMPTS = {\n",
    "    \"BKL\": [\"This is dermatoscopy of pigmented benign keratosis\", 'This is dermoscopy of pigmented benign keratosis'],\n",
    "    \"NV\": [\"This is dermatoscopy of nevus\", 'This is dermoscopy of nevus'],\n",
    "    \"DF\": ['This is dermatoscopy of dermatofibroma', 'This is dermoscopy of dermatofibroma'],\n",
    "    \"MEL\": ['This is dermatoscopy of melanoma', 'This is dermoscopy of melanoma'],\n",
    "    \"VASC\": ['This is dermatoscopy of vascular lesion', 'This is dermoscopy of vascular lesion'],\n",
    "    \"BCC\": ['This is dermatoscopy of basal cell carcinoma', 'This is dermoscopy of basal cell carcinoma'],\n",
    "    \"AKIEC\": ['This is dermatoscopy of actinic keratosis', 'This is dermoscopy of actinic keratosis']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15c6c856-fc05-4cb9-984c-5589d7f891dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_score(image_features_norm,\n",
    "                               prompt_target_embedding_norm,\n",
    "                               prompt_ref_embedding_norm,\n",
    "                               temp=1,\n",
    "                               top_k=-1,\n",
    "                               normalize=True):\n",
    "    \"\"\"\n",
    "    Similarity Score used in \"Fostering transparent medical image AI via an image-text foundation model grounded in medical literature\"\n",
    "    https://www.medrxiv.org/content/10.1101/2023.06.07.23291119v1.full.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    target_similarity = prompt_target_embedding_norm.float() @ image_features_norm.T.float()\n",
    "    ref_similarity = prompt_ref_embedding_norm.float() @ image_features_norm.T.float()\n",
    "\n",
    "\n",
    "    if top_k > 0:\n",
    "        idx_target = target_similarity.argsort(dim=1, descending=True)\n",
    "        target_similarity_mean = target_similarity[:,idx_target.squeeze()[:top_k]].mean(dim=1)\n",
    "        \n",
    "        ref_similarity_mean = ref_similarity.mean(dim=1)\n",
    "    else:\n",
    "        target_similarity_mean = target_similarity.mean(dim=1)\n",
    "        ref_similarity_mean = ref_similarity.mean(dim=1)\n",
    "    \n",
    "    if normalize:\n",
    "        similarity_score = scipy.special.softmax([target_similarity_mean.numpy(), ref_similarity_mean.numpy()], axis=0)[0, :].mean(axis=0)\n",
    "    else:\n",
    "        similarity_score = target_similarity_mean.mean(axis=0)\n",
    "\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d82b8832-b4d9-47c1-8e0f-4ad9ada6ae53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] DATASET: ISIC_2018\n",
      "[INFO] MODEL: ViT-L-14\n"
     ]
    }
   ],
   "source": [
    "print(f\"[INFO] DATASET: {DATASET}\")\n",
    "print(f\"[INFO] MODEL: {MODEL}\")\n",
    "\n",
    "# Load image embeddings \n",
    "img_embeddings = np.load(f\"img_embeddings/image_embeddings_{DATASET}_MONET_{MODEL}_Segmented_Norm.npy\", allow_pickle=True).item()\n",
    "\n",
    "# Load reference embeddings\n",
    "reference_embeddings = torch.from_numpy(np.load(f\"reference_embeddings/reference_concept_embeddings.npy\")).unsqueeze(0)\n",
    "\n",
    "results = dict()\n",
    "# Iterate over images and calculate similarity\n",
    "for im in img_embeddings.keys():\n",
    "    img_feats = torch.from_numpy(img_embeddings[im]).unsqueeze(0)\n",
    "\n",
    "    similarity_scores = []\n",
    "    for disease_label in CLASS_LABELS_PROMPTS.keys():\n",
    "        # Load text embeddings\n",
    "        text_feats = torch.from_numpy(np.load(f\"text_embeddings/class_label_embeddings_{disease_label}.npy\")).unsqueeze(0)\n",
    "\n",
    "        # Calculate similarity\n",
    "        similarity = calculate_similarity_score(image_features_norm=img_feats,\n",
    "                                                prompt_target_embedding_norm=text_feats,\n",
    "                                                prompt_ref_embedding_norm=reference_embeddings,\n",
    "                                                top_k=-1,\n",
    "                                                temp=(1/np.exp(4.5944)),\n",
    "                                                normalize=True)\n",
    "\n",
    "        similarity_scores.append(similarity[0])\n",
    "\n",
    "    # Save score into a dictionary w.r.t. to image\n",
    "    results[im] = similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42832ce5-76a9-41d6-a050-0dde5abd31f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         MEL       0.91      0.90      0.91      1340\n",
      "     NON-MEL       0.29      0.32      0.30       171\n",
      "\n",
      "    accuracy                           0.84      1511\n",
      "   macro avg       0.60      0.61      0.61      1511\n",
      "weighted avg       0.84      0.84      0.84      1511\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1209  131]\n",
      " [ 117   54]] \n",
      "\n",
      "BACC: 0.6090141398271799\n",
      "Sensitivity: 0.3157894736842105\n",
      "Specificity: 0.9022388059701493\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, balanced_accuracy_score, auc\n",
    "\n",
    "if DATASET == \"ISIC_2018\":\n",
    "    gt = pd.read_csv(\"../data/ISIC_2018/image_classes_ISIC_2018.csv\")\n",
    "    \n",
    "    train_images_df = pd.read_csv(\"../data/ISIC_2018/ISIC_2018_train.csv\")\n",
    "    train_images = train_images_df[\"images\"].tolist()\n",
    "    \n",
    "    valiadtion_images_df = pd.read_csv(\"../data/ISIC_2018/ISIC_2018_validation.csv\")\n",
    "    validation_images = valiadtion_images_df[\"images\"].tolist()\n",
    "    \n",
    "    test_images_df = pd.read_csv(\"../data/ISIC_2018/ISIC_2018_test.csv\")\n",
    "    test_images = test_images_df[\"images\"].tolist()\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_pred_probs = []\n",
    "for im in results.keys():\n",
    "    \n",
    "    if str(im) in test_images:\n",
    "        #y_true.append(gt.loc[gt['images'] == str(im)]['labels'].tolist()[0])\n",
    "        y_true.append(1 if gt.loc[gt['images'] == str(im)]['labels'].tolist()[0] == 3 else 0)\n",
    "        y_pred.append(1 if np.argmax(results[im]) == 3 else 0)\n",
    "        y_pred_probs.append(results[im])\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true=y_true, y_pred=y_pred, target_names=[\"MEL\", \"NON-MEL\"]))\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1]\n",
    "FN = conf_matrix[1][0]\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix, \"\\n\")\n",
    "\n",
    "# BACC\n",
    "bacc = balanced_accuracy_score(y_true, y_pred)\n",
    "print(f\"BACC: {bacc}\")\n",
    "\n",
    "# Sensitivity\n",
    "SE = TP / (TP + FN)\n",
    "print(f\"Sensitivity: {SE}\")\n",
    "\n",
    "# Specificity\n",
    "SP = TN / (TN + FP)\n",
    "print(f\"Specificity: {SP}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
